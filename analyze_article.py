#!/usr/bin/env python3

import os
import requests
from bs4 import BeautifulSoup
import openai
import json
import re
import datetime
import hashlib
from dotenv import load_dotenv
import asyncio
from telegram import Bot

# 1. Load config (API keys, tokens) from .env
load_dotenv()
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# 2. Get latest article info using GPT-4o-mini
def get_latest_article():
    url = 'https://www.maobidao.net/'
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    html = response.text[:20000]  # Truncate to avoid token limit
    utc_now = datetime.datetime.now(datetime.timezone.utc)
    beijing_now = utc_now + datetime.timedelta(hours=8)
    now_str = beijing_now.strftime("%Y-%m-%d %H:%M")

    prompt = (
        f"ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©ä»ç½‘é¡µHTMLä¸­æå–æ–‡ç« ä¿¡æ¯çš„åŠ©æ‰‹ã€‚\n"
        f"å½“å‰åŒ—äº¬æ—¶é—´ä¸ºï¼š{now_str}\n"
        "è¯·ä»ä¸‹é¢çš„HTMLä»£ç ä¸­ï¼Œæå–æœ€æ–°ä¸€ç¯‡æ–‡ç« çš„æ ‡é¢˜ã€é“¾æ¥å’Œå‘å¸ƒæ—¶é—´ï¼Œ"
        "å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼ˆæ ¼å¼ä¸º{\"title\": \"...\", \"url\": \"...\", \"time\": \"YYYY-MM-DD HH:mm\"}ï¼‰ã€‚\n\n"
        "HTMLå†…å®¹å¦‚ä¸‹ï¼š\n"
        f"{html}\n"
        "\nåªè¿”å›JSONç»“æœï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"
    )

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=300,
        temperature=0.0,
    )

    content = None
    if hasattr(response, "choices") and response.choices and hasattr(response.choices[0], "message"):
        content = response.choices[0].message.content
    else:
        print("OpenAI è¿”å›å†…å®¹ç»“æ„å¼‚å¸¸ï¼š", response)
        raise RuntimeError("OpenAI è¿”å›ç»“æœä¸å« choices å­—æ®µ")
    match = re.search(r"\{.*\}", content, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group())
            return data["title"], data["url"], data["time"]
        except Exception as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"AIè¿”å›å†…å®¹: {content}")
            raise
    else:
        print("æœªæ‰¾åˆ°JSONå¯¹è±¡ï¼ŒAIåŸå§‹è¿”å›ï¼š", content)
        raise ValueError("AIå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONå¯¹è±¡")

# 3. Fetch and cache article HTML
def get_cached_html(link, cache_dir="article_html_cache"):
    os.makedirs(cache_dir, exist_ok=True)
    filename = hashlib.md5(link.encode("utf-8")).hexdigest() + ".html"
    path = os.path.join(cache_dir, filename)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            html = f.read()
        return html
    resp = requests.get(link, timeout=10)
    resp.raise_for_status()
    html = resp.text
    with open(path, "w", encoding="utf-8") as f:
        f.write(html)
    return html

# 4. Extract all <section> text as main content
def extract_main_text_from_all_sections(html):
    soup = BeautifulSoup(html, "html.parser")
    sections = soup.find_all("section")
    if sections:
        article_text = "\n".join(
            section.get_text(separator="\n", strip=True)
            for section in sections
        )
        return article_text[:4000]  # æˆªæ–­é˜²æ­¢tokenè¿‡å¤š
    else:
        print("æ²¡æœ‰æ‰¾åˆ°<section>æ ‡ç­¾ã€‚")
        return ""

def extract_json_array(text):
    match = re.search(r"\[.*\]", text, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group())
            return data
        except Exception as e:
            print("JSONè§£æå¤±è´¥:", e)
            print("AIåŸå§‹è¾“å‡º:", text)
            return []
    else:
        print("æœªæ‰¾åˆ°JSONæ•°ç»„ï¼ŒAIåŸå§‹è¾“å‡º:", text)
        return []

# 5. Extract mentioned companies with sentiment from article text using GPT-4o-mini
def extract_mentioned_companies(link):
    html = get_cached_html(link)
    article_text = extract_main_text_from_all_sections(html)
    if not article_text.strip():
        print("è­¦å‘Šï¼šæœªæå–åˆ°æ­£æ–‡å†…å®¹ã€‚")
        return []

    prompt = (
        "ä½ æ˜¯ä¸“ä¸šçš„ä¿¡æ¯æŠ½å–åŠ©æ‰‹ã€‚è¯·ä»ä¸‹é¢çš„æ–‡ç« å†…å®¹ä¸­ï¼Œæå–æ‰€æœ‰è¢«æåŠçš„Aè‚¡ä¸Šå¸‚å…¬å¸åç§°ã€‚"
        "å¯¹äºæ¯å®¶è¢«æåŠçš„å…¬å¸ï¼Œè¯·åˆ¤æ–­ä½œè€…å¯¹è¯¥å…¬å¸çš„æœªæ¥æ“ä½œè§‚ç‚¹ï¼ˆä¹°å…¥/å–å‡º/å¿½ç•¥ï¼‰ï¼Œæ³¨æ„å¿½ç•¥æ—©æœŸå†å²å›é¡¾ï¼ŒåªæŠ½å–çœŸæ­£éœ€è¦å…³æ³¨çš„å…¬å¸ã€‚"
        "åŒæ—¶ç»™å‡ºä½œè€…åœ¨æåŠè¿™ä¸ªå…¬å¸æ—¶çš„æ•´ä½“æƒ…ç»ªï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ã€‚\n"
        "è¿”å›æ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š\n"
        "- å­—æ®µ companyï¼šå…¬å¸åç§°\n"
        "- å­—æ®µ stanceï¼šæœªæ¥æ“ä½œè§‚ç‚¹ï¼Œåªèƒ½æ˜¯â€œä¹°å…¥â€â€œå–å‡ºâ€â€œå¿½ç•¥â€ä¹‹ä¸€\n"
        "- å­—æ®µ sentimentï¼šæƒ…ç»ªï¼Œåªèƒ½æ˜¯â€œæ­£é¢â€â€œè´Ÿé¢â€â€œä¸­æ€§â€ä¹‹ä¸€\n"
        "è¯·ä»¥JSONæ•°ç»„è¿”å›ï¼ˆæ ¼å¼ä¸ºï¼š[{\"company\": \"å…¬å¸å\", \"stance\": \"ä¹°å…¥/å–å‡º/å¿½ç•¥\", \"sentiment\": \"æ­£é¢/è´Ÿé¢/ä¸­æ€§\"}, ...]ï¼‰ã€‚\n"
        "å¦‚æ–‡ä¸­æœªæåŠå…¬å¸ï¼Œè¯·è¿”å›ç©ºæ•°ç»„ []ã€‚\n"
        "åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚\n\n"
        f"æ–‡ç« å†…å®¹ï¼š\n{article_text}"
    )

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=4096,
        temperature=0.0,
    )
    content = completion.choices[0].message.content

    companies = extract_json_array(content)
    return companies

# 6. è¯»å–æ‰€æœ‰ chat_id
def get_all_chat_ids(filepath="chat_ids.txt"):
    if not os.path.exists(filepath):
        return []
    with open(filepath, "r") as f:
        return [line.strip() for line in f if line.strip()]

# 7. æ ¼å¼åŒ–æ¨é€æ¶ˆæ¯
def format_message(title, link, time, companies):
    msg = f"ğŸ“¢ çŒ«ç¬”åˆ€æ–°æ–‡ç« \n\næ ‡é¢˜ï¼š{title}\né“¾æ¥ï¼š{link}\n"
    if companies:
        msg += "\næ–‡ç« æ¶‰åŠå…¬å¸ï¼š\n"
        for comp in companies:
            if isinstance(comp, dict):
                msg += f"- {comp.get('stance', '')} {comp.get('company', '')}ï¼ˆæƒ…ç»ªï¼š{comp.get('sentiment', '')}ï¼‰\n"
            else:
                msg += f"- {comp}\n"
    else:
        msg += "\næœªæ£€æµ‹åˆ°å…¬å¸åã€‚"
    return msg

# 8. å¼‚æ­¥å‘é€æ¨é€åˆ°æ‰€æœ‰ chat_id
async def send_telegram_notification(bot_token, chat_ids, message):
    bot = Bot(token=bot_token)
    for chat_id in chat_ids:
        try:
            await bot.send_message(chat_id=chat_id, text=message)
            print(f"å·²å‘é€ç»™ {chat_id}")
        except Exception as e:
            print(f"å‘é€ç»™ {chat_id} å¤±è´¥: {e}")

# 9. ä¸»æµç¨‹
def main():
    title, link, time = get_latest_article()
    print(f"Title: {title}\nLink: {link}\nTime: {time}")

    companies = extract_mentioned_companies(link)
    print("å…¬å¸æŠ½å–ç»“æœï¼š", companies)

    message = format_message(title, link, time, companies)
    print("æ¨é€å†…å®¹ï¼š\n", message)

    chat_ids = get_all_chat_ids()
    if not chat_ids:
        print("æ²¡æœ‰æ‰¾åˆ° chat_idï¼Œæ¨é€å·²è·³è¿‡ã€‚")
        return
    asyncio.run(send_telegram_notification(TELEGRAM_BOT_TOKEN, chat_ids, message))

if __name__ == "__main__":
    main()
